{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirhatamian/Statistical-Models-For-Data-Science/blob/main/Statistical_Models_For_Data_Science_ToDo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vwlvCefS_Bl"
      },
      "source": [
        "# Write your own Google drive path to files\n",
        "DrivePath = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "\n",
        "# Link to Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urUXcr8BSo38"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "print (np.__version__)\n",
        "print(pd.__version__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FqhFH3BTFVj"
      },
      "source": [
        "#**Brief Recall to Numerical Python (NumPy)**\n",
        "\n",
        "NumPy represents the fundamental library required for high performance scientific computing and data analysis. It is the foundation on which\n",
        "many other higher-level tools are built. Some of the main things it\n",
        "provides are: \\\\\n",
        "• *ndarray*, a fast and space-efficient multidimensional array providing vectorized arithmetic operations and sophisticated broadcasting capabilities; \\\\\n",
        "• standard mathematical functions for fast operations on entire arrays of data\n",
        "without having to write loops; \\\\\n",
        "• tools for reading/writing array data; \\\\\n",
        "• linear algebra, random number generation, and Fourier transform capabilities.\n",
        "\n",
        "In what follows, we briefly recall how arrays of data are handled in the Python language by built-in functions and how NumPy improves on this (note: Python includes several built-in container types, that are lists, dictionaries, sets, and tuples.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIMPJgYMVJtT"
      },
      "source": [
        "###**List, Indexing and Slicing**\n",
        "\n",
        "A **list** represents the basic ordered and mutable data collection type in Python, holding items that can be of different nature. For example we can merge numbers with strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx8ItRVgVEe_"
      },
      "source": [
        "# Basic Notions\n",
        "myNumbers = [4, 5, 6, 7]\n",
        "print(myNumbers)\n",
        "print('My first number is ' + str(myNumbers[0]))\n",
        "\n",
        "string1 = [str(c) for c in myNumbers] # list of strings\n",
        "print(string1) # print(type(string1[0])) <class 'str'>\n",
        "\n",
        "print('---------------')\n",
        "myNumbers.append(10) # To add an element to the list\n",
        "print(myNumbers)\n",
        "\n",
        "print('---------------')\n",
        "myNumbers.pop(1) # To remove an element, pop(N) defines the Nth position to be removed\n",
        "print(myNumbers)\n",
        "\n",
        "# myNumbers.pop() # if no position is given as input, the last item is removed\n",
        "# print(myNumbers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_1f8q9BVmdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0231fce1-0fdc-4d10-a570-eb2e190c33df"
      },
      "source": [
        "# Creating a List\n",
        "L1 = list(range(10)) # range returns a sequence of numbers, starting from 0 (by default), with increments = 1 (by default), and stops before a specified number.\n",
        "print(L1)\n",
        "\n",
        "L2 = list(range(1,10,2)) # start, stop, step (note: stop is not included)\n",
        "print(L2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[1, 3, 5, 7, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI_M92U5XgWn"
      },
      "source": [
        "# Indexing Arrays: getting (and eventually setting) the value of individual array elements\n",
        "X = [5, 0, 3, 3, 7, 9]\n",
        "print(X[0]) # single element\n",
        "print(X[-2]) # negative index is used to index from the end of the array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhyoCbWYWa5z"
      },
      "source": [
        "# Slicing of arrays: getting (and eventually setting) smaller subarrays within a larger array\n",
        "X = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "print(X)\n",
        "print(X[5:]) # if no end position is defined, the slicing goes up to the end of the list (step 1 by default)\n",
        "print(X[:5]) # if no start position is defined, the slicing starts from the first item of the list, and stop not included (step 1 by default)\n",
        "\n",
        "# Note = X[start:stop:step] (remember, stop not included)\n",
        "print(X[::2])  # every other element, starting at the first position\n",
        "print(X[1::2]) # every other element, starting at index 1\n",
        "print(X[0:5:]) # same as before, extended way\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghtlR715dFnR"
      },
      "source": [
        "# Note: a potentially confusing case is when the step value is negative. In this case, the defaults for start and stop are swapped.\n",
        "print(X[::-1])  # all elements, reversed\n",
        "print(X[5::-2]) # reversed every other from index 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR6zlTvvVaWo"
      },
      "source": [
        "###**Other important data types: Tuples and Dictionaries**\n",
        "\n",
        "Besides the lists seen above, tuples and dictionaries are also important data types we can use in Python. A **tuple** is similar to a list, but it is created with parentheses instead of square brackets. The main difference is that, while the list is mutable, a tuple is immutable. So tuples are ordered, unchangeable, heterogenous, and allow duplicate values. \\\\\n",
        "\n",
        "A Python **dictionary** is a hash table or a hash mapping (associative arrays). Dictionaries are indexed with keys, which can be any immutable type. For example, a string or number can be a key. Thus, dictionaries represent a *key:value* mapping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcLB0VdmVnZ1"
      },
      "source": [
        "# Tuple\n",
        "simple_tuple = (1, 5, 6, 4, 2)\n",
        "print(simple_tuple)\n",
        "\n",
        "slic = simple_tuple[0:3] # Slicing\n",
        "print(slic)\n",
        "\n",
        "# Note: Tuple can not be sorted, differently from lists\n",
        "animals = ['cat','fish', 'penguin','dog']\n",
        "animals.sort()\n",
        "print(animals)\n",
        "\n",
        "# simple_tuple.sort() # This would give error!\n",
        "\n",
        "# To convert a tuple into a list\n",
        "# t = list(slic)\n",
        "# print(t)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9s3z_v0nhMC"
      },
      "source": [
        "# Simple dictionary\n",
        "simple_dict = {'five':5, 'three':3, 'one':1} # To create the dictionary\n",
        "print(simple_dict)\n",
        "print(simple_dict ['five']) # To access the data\n",
        "\n",
        "# Adding new items to a dictionary\n",
        "simple_dict['ninety'] = 90\n",
        "print(simple_dict)\n",
        "\n",
        "# Note: Dictionary are ordered (insertion order).\n",
        "# To sort a dictionary in alphabetic order:\n",
        "# print(dict(sorted(simple_dict.items())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL9WVdJP5Gj0"
      },
      "source": [
        "# More complex dictionary\n",
        "ex1 = {'four': [8, 4.0],\n",
        "       'two': 'London',\n",
        "       'three': list(range(3)),\n",
        "       'one': np.ones([1,5],dtype=int)}\n",
        "\n",
        "print(ex1) # insertion order\n",
        "print(dict(sorted(ex1.items()))) # alphabetic order\n",
        "# print(ex1['four'])\n",
        "# list(ex1.keys()) # To check the keys\n",
        "# list(ex1.values()) # To check the values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqu3dJtuZGxA"
      },
      "source": [
        "###**Creating Arrays from Python Lists with NumPy**\n",
        "\n",
        "The *np.array()* can be used to efficiently create arrays from Python lists. Indeed, one of the key features given by NumPy is its N-dimensional array object *ndarray*, used to represent both matrices and vectors being a fast and flexible container for large data sets. NumPy arrays are faster and more compact than Python lists. Indeed, an array consumes less memory and is convenient to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8ceNNniZLGL"
      },
      "source": [
        "data = list(range(2,20,2))\n",
        "b = np.array(data) #1D Row vector\n",
        "print(b)\n",
        "print(type(data))\n",
        "print(type(b))\n",
        "print('--------------')\n",
        "\n",
        "# Alternative to performing list(range()) + np.array():\n",
        "b2 = np.arange(2,20,2) # as command range(), but returns an ndarray instead of a range object (or list if we use list(range()))\n",
        "print(b2)\n",
        "print(type(b2))\n",
        "print('--------------')\n",
        "\n",
        "c = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) # 3x3 matrix\n",
        "print(c)\n",
        "print('--------------')\n",
        "# Note: we can also specify the type, appending for example \",dtype=np.float64\"\n",
        "\n",
        "# New elements can be added to a previously defined array (mutability property):\n",
        "a2 = np.insert(b,2,[100,200]) # The second element defines the position where to add the new elements\n",
        "print(a2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuUhJtWBarj1"
      },
      "source": [
        "# To access the data in the NumPy array/matrix\n",
        "# Few examples with matrices\n",
        "print(c)\n",
        "print('')\n",
        "\n",
        "print(c[:2, :2]) # part of the matrix (ending term is not included)\n",
        "print('')\n",
        "\n",
        "print(c[1,1]) # To access a specific item\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9q903-IeLEy"
      },
      "source": [
        "# Note: to create simulated random integer data, the NumPy random number generator can be used:\n",
        "np.random.seed(0)  # seed for reproducibility\n",
        "\n",
        "# function: random.randint(low, high=None, size=None, dtype=int).\n",
        "# If high is None (the default), then results are from [0, low).\n",
        "x1 = np.random.randint(100, size=6)  # 1D array\n",
        "x2 = np.random.randint(10, size=(3, 4))  # 2D array (matrix)\n",
        "\n",
        "print(x1)\n",
        "print(x2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtOPckXle7xW"
      },
      "source": [
        "Each ndarray has a set of attributes, given by *ndim* (the number of dimensions), *shape* (the size of each dimension) and *size* (the total size of the array). Another useful attribute is *dtype*, which stores the information regarding the data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQsQF4aCe6tc"
      },
      "source": [
        "print(\"x2 ndim: \", x2.ndim)\n",
        "print(\"x2 shape:\", x2.shape)\n",
        "print(\"x2 size: \", x2.size)\n",
        "print(\"x2 dtype:\", x2.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m29zkIkygB_C"
      },
      "source": [
        "###**Array Reshaping and Concatenation**\n",
        "\n",
        "A useful operation that can be done when dealing with data is the **reshaping of arrays**, allowing to change the shape of a given array without modifying the content. Indeed, the number of elements in the initial and final arrays is the same. The most flexible way of doing this is with the *reshape* function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY9gcVpX902D"
      },
      "source": [
        "Row_V_1D = np.array([1, 2, 3, 4 ]) # ndim = 1, 1D Array (a single list/array of elements)\n",
        "Row_V_2D = np.reshape(Row_V_1D,(1,4)) # ndim = 2, 2D Array\n",
        "Col_V = np.reshape(Row_V_1D,(4, 1)) # ndim=2, alternative: Col_V = Row_V_2D.T\n",
        "\n",
        "print(Row_V_1D)\n",
        "print(Row_V_2D)\n",
        "print(Col_V)\n",
        "print('------')\n",
        "print(\"Row_V_1D shape: \", Row_V_1D.shape)\n",
        "print(\"Row_V_2D shape: \", Row_V_2D.shape)\n",
        "print(\"Col_V shape: \", Col_V.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX_kEkxNgU2S"
      },
      "source": [
        "T = np.array(range(10))\n",
        "print(T)\n",
        "T_reshaped_to_2D = np.reshape(T, (-1, 2)) # -1 means that the number of rows in unknown and NumPy will define it, according to the other dimension/elements\n",
        "print(T_reshaped_to_2D)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9hNJxcrDe_i"
      },
      "source": [
        "# As an alternative to reshape, we could use the np.newaxis that will increase the dimensions of our array by one dimension:\n",
        "a = np.array([2, 4, 6]) # 1D array\n",
        "a_expanded = a[np.newaxis, :] # 2D Row array, otherwise: a_expanded = a[:,np.newaxis] for Column\n",
        "\n",
        "print(a)\n",
        "print(a_expanded)\n",
        "print(\"a shape: \", a.shape)\n",
        "print(\"a dim: \", a.ndim)\n",
        "print(\"a_expanded shape: \", a_expanded.shape)\n",
        "print(\"a_expanded dim: \", a_expanded.ndim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFVAzHuwOUZO"
      },
      "source": [
        "In addition, it is possible to combine multiple arrays into one, performing an array concatenation (*np.concatenate*). This takes a tuple or list of arrays as its first argument:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyxq-oYGOrcZ"
      },
      "source": [
        "# For 1D Arrays\n",
        "x = np.array([1, 2, 3])\n",
        "y = np.array([3, 2, 1])\n",
        "z = np.array([0, 1])\n",
        "Conc = np.concatenate([x, y, z]) # We can concatenate even more arrays\n",
        "print(Conc)\n",
        "print(Conc.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSFghscBPEpQ"
      },
      "source": [
        "# For Matrices\n",
        "grid = np.array([[1, 2, 3],\n",
        "                 [4, 5, 6]])\n",
        "print(grid)\n",
        "print('')\n",
        "\n",
        "M1 = np.concatenate((grid,grid)) # default is axis=0\n",
        "print(M1)\n",
        "print('')\n",
        "\n",
        "M2 = np.concatenate((grid,grid),axis=1)\n",
        "print(M2)\n",
        "print('------')\n",
        "\n",
        "y = np.array([10,11,12]) # 1D array\n",
        "y_r = np.reshape(y,(1,len(y))) # 2D array\n",
        "M3 = np.concatenate((grid,y_r)) # I can not directly concatenate using y as it is 1D array, so should be converted to 2D first\n",
        "print(y_r)\n",
        "print(M3)\n",
        "print('------')\n",
        "\n",
        "# Alternative for this last operation:\n",
        "M4 = np.vstack((grid,y)) # vstack stack arrays in sequence vertically (row wise). hstack for stacking arrays in sequence horizontally, column wise.\n",
        "print(M4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0e-mYwo6DJ0"
      },
      "source": [
        "###**Structured Data: Structured Arrays**\n",
        "\n",
        "When dealing with a heterogeneous set of data, which can not be easily stored in traditional arrays for further operations, NumPy provides an efficient storage. Suppose we have different information stored in separate arrays, they can be compounded in a structured array using a similar sintax:\n",
        "\n",
        "```\n",
        "# data = np.zeros(N, dtype={'names':('A', 'B', 'C'),\n",
        "                          'formats':((np.str_, 10), int, np.float32)})\n",
        "data['A'] = A\n",
        "data['B'] = B\n",
        "data['C'] = C\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8uErXbJ5rVB"
      },
      "source": [
        "name = ['Alice', 'Bob', 'Cathy', 'Doug']\n",
        "age = [25, 45, 37, 9]\n",
        "weight = [55.2, 85.5, 68.1, 31.5]\n",
        "\n",
        "data = np.zeros(4, dtype={'names':('name', 'age', 'weight'),\n",
        "                          'formats':((np.str_, 10), int, np.float32)})\n",
        "#print(data.dtype)\n",
        "\n",
        "# This above is an empty container that we have to fill with the corresponding information:\n",
        "data['name'] = name\n",
        "data['age'] = age\n",
        "data['weight'] = weight\n",
        "print(data)\n",
        "\n",
        "# To access some elements in the structured array:\n",
        "print(data['age']) # To access data according to the label index (e.g. all ages)\n",
        "print(data[2]['weight']) # To access a specific variable in a Nth position"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mOQgCI7LnLS"
      },
      "source": [
        "##**2. Introducing Pandas Objects**\n",
        "\n",
        "In Section 1, we have given some basic recalls to NumPy and its important *ndarray* object, while in the next section we will build on this knowledge by looking at the data structures provided by the Pandas library. Pandas is a newer package built on top of NumPy, which provides an efficient implementation of a **DataFrame**, among the others. DataFrames are essentially multidimensional arrays with attached row and column labels, and often with heterogeneous types and/or missing data. \\\\\n",
        "Thus, at the very basic level, Pandas objects can be seen as an enhanced versions of NumPy structured arrays where the rows and columns are identified with labels rather than simple integer indices. Let's start from the three fundamental Pandas data structures: Series, Index, and DataFrame.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jDA31_VJK7_"
      },
      "source": [
        "**2.1 The Pandas Series and Index Objects**\n",
        "\n",
        "A Pandas Series is a 1D array of indexed data. It can be created from a list or array. The Series wraps both a sequence of values and a sequence of indices, which can be accessed with the **values** and **index** attributes, respectively. The *values* are simply a NumPy array, while the *index* is an immutable sequence storing axis labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcNiyjbzPDG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7e1ddc-a367-4311-bf9a-4c2349e5af03"
      },
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0], index=[5,8,9,7])\n",
        "#data = pd.Series([0.25, 0.5, 0.75, 1.0]) # default index values [0,1,2,3]\n",
        "\n",
        "print(data.values)\n",
        "print(list(data.index))\n",
        "print('Values type:', type(data.values))\n",
        "print('Index type:', type(data.index))\n",
        "print('-----------------')\n",
        "\n",
        "# Dictionary-like expression to examine the keys/indices (Series as a specialization of a Python dictionary)\n",
        "print(list(data.keys())) # To examine the index\n",
        "print(list(data.items())) # To examine the values\n",
        "\n",
        "# data['e'] = 1.25 # To add or modify a specific element"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.25 0.5  0.75 1.  ]\n",
            "[5, 8, 9, 7]\n",
            "Values type: <class 'numpy.ndarray'>\n",
            "Index type: <class 'pandas.core.indexes.numeric.Int64Index'>\n",
            "-----------------\n",
            "[5, 8, 9, 7]\n",
            "[(5, 0.25), (8, 0.5), (9, 0.75), (7, 1.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple slicing and indexing\n",
        "print(data[0:2]) # Simple slicing, referring to the positions\n",
        "print(data[8]) # Indexing, referring to the index"
      ],
      "metadata": {
        "id": "idT5GFE-gR7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUR2qrO0RkWG"
      },
      "source": [
        "*Main difference with 1D NumPy array:* presence of the index. Indeed while the Numpy array has an <u>implicitly </u>defined integer index used to access the values, the Pandas Series has an <u>explicitly </u> defined index associated with the values. This explicit definition gives more capabilities to the Series object, e.g. the index can consist of values of any desired type (also strings)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRUyQC8KRj3o"
      },
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
        "                 index=['a', 'b', 'c', 'd'])\n",
        "print(data)\n",
        "print(data['c'])\n",
        "print(data['c':'d'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Pandas Index object can be seen as an immutable array or as an ordered set. If we construct an Index from a list of integers:"
      ],
      "metadata": {
        "id": "40wlNVPtifo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind = pd.Index([2, 3, 5, 7, 11])\n",
        "print(list(ind))\n",
        "print(list(ind[::2]))\n",
        "# Index as immutable array -> it broadly operates as a simple array, but cannot be changed\n",
        "# ind[1] = 0 -> this will give an error!\n",
        "\n",
        "# Index as ordered set\n",
        "#indA = pd.Index([1, 3, 5, 7, 9])\n",
        "#indB = pd.Index([2, 3, 5, 7, 11])\n",
        "#indA & indB # intersection"
      ],
      "metadata": {
        "id": "DOBMr0YcibI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl9hLrFfTabX"
      },
      "source": [
        "Thus, to construct Pandas Series objects, the general syntax is: \\\\\n",
        "> `pd.Series(data, index=values) where index is optional ` \\\\\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja5qTMkPVlTK"
      },
      "source": [
        "T0 = pd.Series(['a','b','c'], index=[2,1,3])\n",
        "print(T0)\n",
        "\n",
        "# Alternative for the same result {index:value}\n",
        "T1 = pd.Series({2:'a', 1:'b', 3:'c'})\n",
        "print(T1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides the examples above and as we already mentioned, data can be a dictionary in which index refers to the dictionary keys:"
      ],
      "metadata": {
        "id": "1zXJdE4ybtK1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS3ndONxVEMr"
      },
      "source": [
        "# Example of a dictionary and conversion to a Series object\n",
        "population_dict = {'California': 38332521,\n",
        "                   'Texas': 26448193,\n",
        "                   'New York': 19651127,\n",
        "                   'Florida': 19552860,\n",
        "                   'Illinois': 12882135}\n",
        "print(population_dict)\n",
        "print('Type population dict:', type(population_dict))\n",
        "print('-----')\n",
        "\n",
        "population = pd.Series(population_dict)\n",
        "print(population)\n",
        "print('Type population:', type(population))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khwZbw1E8Xe_"
      },
      "source": [
        "# Slicing can be performed with two different methods, as we have labels as indexes:\n",
        "print(population['Texas':'Florida']) # slicing by explicit index\n",
        "print('---------')\n",
        "print(population[1:4]) # slicing by implicit integer index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9V8zdAB4hlS"
      },
      "source": [
        "<u>Important Note:</u> Among the possible operations, slicing may be a source of confusion. Indeed, when slicing with an explicit index (i.e., `data['a':'c']`), the final index is included in the slice, while when slicing with an implicit index (i.e., `data[0:2]`), the final index is excluded from the slice!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
        "                 index=['a', 'b', 'c', 'd'])\n",
        "print(data)\n",
        "print('')\n",
        "print(data['b':'d']) # slicing by explicit index\n",
        "print('')\n",
        "print(data[1:3]) # slicing by implicit integer index\n",
        "\n",
        "# Note: when dealing with integer values as index the confusion can be increased for slicing and indexing!\n",
        "#data = pd.Series(['a', 'b', 'c','d'], index=[1, 3, 5, 10])\n",
        "#print(data)\n",
        "#print(data[10]) # explicit index when indexing --> d\n",
        "#print(data[1:3]) # implicit index when slicing --> 3 b\n",
        "#                                                   5 c"
      ],
      "metadata": {
        "id": "KJbYTRLPHquI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OvzDOVF9R-U"
      },
      "source": [
        "As slicing and indexing conventions can be a source of confusion, Pandas provides some special *indexer attributes* that explicitly expose the indexing schemes. These are *loc* and *iloc*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guLJEB-F-gAa"
      },
      "source": [
        "# loc attribute allows indexing and slicing to refer to the explicit index\n",
        "data = pd.Series(['a', 'b', 'c','d'], index=[1, 3, 5, 10])\n",
        "print(data)\n",
        "print('----')\n",
        "print(data.loc[1])\n",
        "print('----')\n",
        "print(data.loc[1:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjj6c2Jr-nvj"
      },
      "source": [
        "# iloc attribute allows indexing and slicing to refer to the implicit Python-style index\n",
        "print(data)\n",
        "print('----')\n",
        "print(data.iloc[1])\n",
        "print('----')\n",
        "print(data.iloc[1:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOJ-di4f-AZd"
      },
      "source": [
        "**2.2 The Pandas DataFrame Object**\n",
        "\n",
        "Similarly to Series, DataFrame can be seen as a generalization of a NumPy multidimensional array or as a specialization of a Python dictionary.\n",
        "A DataFrame is basically a tabular data structure, with rows and columns. Rows have a specific index to access them, as seen before, while the columns are a collection of Series objects. Therefore, the DataFrame objects can be seen as a spreadsheet, but it is much more flexible. \\\\\n",
        "Here an example, taking some of the data seen above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roN7hpPCdenk"
      },
      "source": [
        "# Create a DataFrame from two dictionaries (dictionary + conversion to series)\n",
        "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
        "             'Florida': 170312, 'Illinois': 149995}\n",
        "area = pd.Series(area_dict)\n",
        "\n",
        "population_dict = {'California': 38332521,\n",
        "                   'Texas': 26448193,\n",
        "                   'New York': 19651127,\n",
        "                   'Florida': 19552860,\n",
        "                   'Illinois': 12882135}\n",
        "population = pd.Series(population_dict)\n",
        "\n",
        "states = pd.DataFrame({'Popul.': population,\n",
        "                       'Area': area})\n",
        "\n",
        "states  # you can try states.shape or states.ndim to check the dimensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckg5q6AufCBr"
      },
      "source": [
        "# Two important attributes on DataFrame\n",
        "print(states.index)\n",
        "print(states.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HupNaQl98El"
      },
      "source": [
        "Below some examples on how to construct a DataFrame from scratch:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEltfftegk1h"
      },
      "source": [
        "# From a single Series object\n",
        "pd.DataFrame(population, columns=['Pop.Number']) # Note: if we add index = [1,2,3,4,5] or any other value it will return all NaN as \"population\" (series type)\n",
        "                                                 # has already an index object (check with population.index)\n",
        "# pd.DataFrame({'Pop.Number': population}) # alternative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTJcd2NGhIOo"
      },
      "source": [
        "# From a 2D-array\n",
        "np.random.seed(42)\n",
        "c = np.array([[1, 2, 3, 10], [4, 5, 6, 11], [7, 8, 9, 21]]) # 3x4 matrix\n",
        "pd.DataFrame(c,\n",
        "             columns=['first', 'second', 'third', 'fourth'],\n",
        "             index=['n1', 'n2', 'n3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W95JlJRgquY"
      },
      "source": [
        "# From a simple list\n",
        "data = [{'a': 1, 'b': 2}, {'b': 3, 'c': 4}] # Two rows\n",
        "pd.DataFrame(data) # the missing values are filled with NaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRxKdgBpAScE"
      },
      "source": [
        "The individual Series that compose the columns of the DataFrame can be accessed via dictionary-style indexing of the column name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoavBV4MAVHw"
      },
      "source": [
        "# Previous example\n",
        "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
        "                  'New York': 141297, 'Florida': 170312,\n",
        "                  'Illinois': 149995})\n",
        "pop = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
        "                 'New York': 19651127, 'Florida': 19552860,\n",
        "                 'Illinois': 12882135})\n",
        "data = pd.DataFrame({'area':area, 'pop':pop})\n",
        "data['area']\n",
        "# data['density'] = data['pop'] / data['area'] -> in this way we can append a new column to the previous DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5wDa4W7BDCg"
      },
      "source": [
        "When it comes to indexing of a DataFrame object, the dictionary-style indexing of columns limits the possibility to treat it as a NumPy array. In particular, passing a single index to an array accesses a row while using the column name would give access to the column itself. In this case, loc, iloc and ix indexers seen above can help to treat this object as if it is a NumPy array. For example:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "ZadIhaujnk5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O355Nw8B4pL"
      },
      "source": [
        "data.iloc[:3, :1] # use implicit indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUZb9c43B2TP"
      },
      "source": [
        "data.loc[:'Florida', :'area'] # use explicit index and column names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWd_nfGnirCV"
      },
      "source": [
        "### **Short Exercise 1:**\n",
        "\n",
        "Create from scratch a DataFrame object with three rows (A,B,C) and three columns (Names, Weight and Age), in order to store information related to three subjects (Tom, Peter and Alexander), their weights (66,55,89) and age. In particular, for the variable age generate random values between 30 and 50.\n",
        "Try to explore different possibilities. \\\\\n",
        "Then, add a fourth column (Height) with values of your choice, and reorder the columns to have 'Name, Age, Height, Weight'. How can you access the data once the object of interest has been created?\n",
        "Finally, sort the entries according to the Age values (descending order, hint: use dataFrame.sort_values(), for having a quick look at the documentation: `help(pd.DataFrame.sort_values)`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRFcA4vO5eO-"
      },
      "source": [
        "###**2.3 Merging Data**\n",
        "\n",
        "In some cases, it might be useful to merge the data we have stored in different DataFrames in order to have all in a single object.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UBwbK_f5jT6"
      },
      "source": [
        "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
        "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
        "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
        "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
        "display(df1, df2)\n",
        "\n",
        "# Combination:\n",
        "df3 = pd.merge(df1, df2, on='employee')\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPPZSFER6WcG"
      },
      "source": [
        "Sometimes the two datasets we have to merge have different column names. In this case, we can use the left_on and right_on keywords to specify the two column names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcKwpFNN6cc9"
      },
      "source": [
        "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
        "                    'salary': [70000, 80000, 120000, 90000]})\n",
        "df4_merge = pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\")\n",
        "display(df4_merge)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWyynx5E6p6a"
      },
      "source": [
        "# The result has a redundant column that we can drop, for example by using the drop() method of DataFrames:\n",
        "df4_merge.drop('name',axis=1,inplace=True)\n",
        "print(df4_merge.index)\n",
        "df4_merge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkLPhSwzIHBF"
      },
      "source": [
        "# Sometimes it might be useful to merge on an index rather than a column.\n",
        "# df.set_index allows to set the DataFrame index using existing columns, i.e. we transform a previous column into an index:\n",
        "df1a = df1.set_index('employee')\n",
        "df2a = df2.set_index('employee')\n",
        "display(df1a, df2a)\n",
        "df4_merge = pd.merge(df1a, df2a, on='employee')\n",
        "display(df4_merge)\n",
        "print(df1a.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extra - Additional useful operations"
      ],
      "metadata": {
        "id": "9OexNESBdBaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Replacing all Occurrences of a String in a DataFrame\n",
        "df = pd.DataFrame({\"Student1\":['OK','Awful','Acceptable'],\n",
        "                   \"Student2\":['Perfect','Awful','OK'],\n",
        "                   \"Student3\":['Acceptable','Perfect','Poor']})\n",
        "print(df)\n",
        "\n",
        "# Replace the strings by numerical values (0-4)\n",
        "df.replace(['Awful', 'Poor', 'OK', 'Acceptable', 'Perfect'], [0, 1, 2, 3, 4])"
      ],
      "metadata": {
        "id": "bF_kXNkDIm26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Applying simple functions to columns or rows in a DataFrame\n",
        "triple = lambda x: x*3\n",
        "# This allows defining a small function without using the \"def\" keyword.\n",
        "# In this case, the lambda function takes one argument \"x\" and returns the result of multiplying it by 3.\n",
        "# e.g, triple(4) returns the result of the operation\n",
        "\n",
        "df = pd.DataFrame(data=np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['A', 'B', 'C'])\n",
        "print(df)\n",
        "\n",
        "# Apply the triple function to the entire df or to a specific column, e.g. df['A'].apply(triple)\n",
        "print(df.apply(triple))\n",
        "\n",
        "# Apply the triple function to a specific row\n",
        "print(df.loc[1].apply(triple))"
      ],
      "metadata": {
        "id": "SB5EUucxGxQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Save DataFrame in a CSV file\n",
        "import os\n",
        "df.to_csv(os.path.join(DrivePath, 'myDataFrame.csv'), sep='\\t')"
      ],
      "metadata": {
        "id": "96zIhAQCI1Bc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}